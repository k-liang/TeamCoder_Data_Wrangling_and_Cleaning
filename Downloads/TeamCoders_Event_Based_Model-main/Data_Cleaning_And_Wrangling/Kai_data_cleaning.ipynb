{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling and Visualization workbook\n",
    "This workbook will be used to generate the data file that will be ready for use in the Event Based Model. Along the way, you will need to implement some of the data cleaning, data wrangling and data visualization skills that you learned in the demonstration notebook using the WHO cases data.  In the project notebook below, you will find instructions for what to do in each step followed by an empty code cell to enter your work. Don't forget that you will need to import the appropriate packages for this work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your import steps here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Load in ADNIMERGE\n",
    "The first step we must do is to identify the measurements that will be used as features in the Event Based Model. From [Alex Young's original paper](https://academic.oup.com/brain/article/137/9/2564/2848155), the features that are to be included are: \n",
    "* Cerebrospinal Fluid (CSF) INNO-BIA AlzBio3 immunoassay ('INNO')\n",
    "  * Amyloid Beta 1-42\n",
    "  * phosphorylated tau\n",
    "  * total tau\n",
    "* Volumetric measurements from **1.5T** magnetic resonance imaging (MRI)\n",
    "  * Whole brain volume\n",
    "  * Ventricular volume\n",
    "  * Entorhinal cortex volume\n",
    "  * Hippocampal volume\n",
    "  * Middle temporal cortex volume\n",
    "  * Fusiform cortex volume \n",
    "  * Annualised whole brain atrophy between 0 and **12 months** using Boundary Shift Integral (BSI)\n",
    "  * Annualised hippocampal atrophy between 0 and **12 months** using Boundary Shift Integral (BSI)\n",
    "* Cognitive measures\n",
    "  * Mini mental state examination (MMSE)\n",
    "  * ADAS-COG13\n",
    "  * Rey Auditory Verbal Learning Test (RAVLT)\n",
    "\n",
    "Many of these features should be available in the ADNI MERGE dataset. The file is donwloaded from Teams and is called `adnimerge_ideas_merge_26may2022.csv`. We have included both the data dictionary and the methods so that you can better understand how this spreadsheet was created and what it represents. Please load in the ADNIMERGE spreadsheet. \n",
    "Here are some of the questions:\n",
    "* Which column identifies the subject?\n",
    "* Can you identify the features above in the column? \n",
    "* Are any of the features above missing?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qx/csfp5_y57613ykhb2sbzl1lh0000gn/T/ipykernel_68891/2173194490.py:4: DtypeWarning: Columns (20,105,116) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_raw = pd.read_csv(input_file)\n"
     ]
    }
   ],
   "source": [
    "# Your answer to Step 1\n",
    "# Below put your code that will load up the ADNI MERGE spreadsheet\n",
    "input_file = 'ADNI/adnimerge_ideas_merge_26may2022.csv'\n",
    "df_raw = pd.read_csv(input_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Filter data\n",
    "The event based model primarily works on cross-sectional data. In the data, the features you have identified from ADNIMERGE should be coming from the **baseline** visit and from scans acquired on a **1.5T** scanner.  Figure out how to filter the rows according to these two criteria. The resulting data frame should have 818 rows remaining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(818, 120)\n"
     ]
    }
   ],
   "source": [
    "# Your answer to Step 2\n",
    "# Below put your code that will filter the ADNI MERGE spreadsheet\n",
    "df_raw['FLDSTRENG'].value_counts()\n",
    "df_raw['Month'].value_counts()\n",
    "df_month = df_raw.loc[df_raw['Month'] == 0]\n",
    "#print(df_month)\n",
    "df_fld_month = df_month.loc[df_month['FLDSTRENG'] == '1.5 Tesla MRI']\n",
    "print(df_fld_month.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Merging data\n",
    "You should have identified that some features from the original list that are missing in the ADNI MERGE spreadsheet. There is another spreadsheet in the data folder called `ucl_bsi_ideas_merge_26may2022.csv` where you will find the additional data.\n",
    "\n",
    "In order to combine data you need to *merge* the two data sets. This involves finding key identifiers (the \"on\" columns) that will correspond to the same subject in both spreadsheets, so that the columns can be combined together in one data frame. Please remember that we only need BSI values from 0 to 12 months, so think about what filtering you will need to do with the new spreadsheet that you are loading in before performing the merge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 98)\n"
     ]
    }
   ],
   "source": [
    "# Your answer to Step 3\n",
    "# Below put your code that will merge the ADNI MERGE spreadsheet\n",
    "# with other ADNI data availale.\n",
    "input_file = 'ADNI/ucl_bsi_ideas_merge_26may2022.csv'\n",
    "df_ucl = pd.read_csv(input_file)\n",
    "\n",
    "#To filter out non-ADNI1 and MRI sequence != 1.5\n",
    "df_ucl_one= df_ucl.groupby(['MRSEQUENCE'])\n",
    "df_ucl_adni= df_ucl_one.get_group('ADNI1')\n",
    "\n",
    "df_ucl_adni_mri= df_ucl_adni[df_ucl_adni['MRFIELD']==1.5]\n",
    "\n",
    "#To filter only BSI 0-12m\n",
    "filtering_values = ['m06','sc','bl']\n",
    "df_ucl_filtered = df_ucl_adni_mri[df_ucl_adni_mri['VISCODE2'].isin(filtering_values)]\n",
    "\n",
    "#print(df_ucl_filtered)\n",
    "\n",
    "#Merge\n",
    "df_merged = pd.merge(df_fld_month, df_ucl_filtered,\n",
    "                       how='outer', on=['RID', 'VISCODE'],\n",
    "                      )\n",
    "df_merged = df_complete.reset_index(drop=True)\n",
    "print(df_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Remove unneeded columns\n",
    "After the merge, how many columns are there? There should be way more columns than what are needed for the event based model. So we can get rid of unwanted columns that we don't need for the replication. You should have:\n",
    "* 14 feature columns from the list in Step 1\n",
    "* Additional columns that should be include, such as:\n",
    "    * subject identifiers (IDs, visit codes, exam dates, site, protocols)\n",
    "    * demographics (Age, Gender)\n",
    "    * diagnoses\n",
    "    * _APOE_ genetic status\n",
    "    * intracranial volume, to serve as a proxy for head size.\n",
    "    * image quality control (QC) variables (such as `TEMPQC`,`REGRATING`)\n",
    "    * anything else you find relevant. I chose to keep 49 columns, but you may have a few more or a few less. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 56)\n"
     ]
    }
   ],
   "source": [
    "# Your answer to Step 4\n",
    "# Below put your code that will remove \n",
    "# unnecessary columns from the data frame.\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "#print(df_merged.columns.tolist())\n",
    "\n",
    "df_complete_trial = df_merged.drop(columns = ['FSVERSION','EXAMDATE_bl', 'CDRSB_bl', 'ADAS11_bl', 'ADAS13_bl', 'ADASQ4_bl', 'MMSE_bl', 'RAVLT_immediate_bl', 'RAVLT_learning_bl', 'RAVLT_forgetting_bl', 'RAVLT_perc_forgetting_bl', 'mPACCdigit_bl', 'mPACCtrailsB_bl', 'FLDSTRENG_bl', 'FSVERSION_bl', 'IMAGEUID_bl', 'Ventricles_bl', 'Hippocampus_bl', 'WholeBrain_bl', 'Entorhinal_bl', 'Fusiform_bl', 'MidTemp_bl', 'ICV_bl', 'MOCA_bl', 'ABETA_bl', 'TAU_bl', 'PTAU_bl', 'Years_bl', 'Month_bl',\n",
    "                                             'MOCA_bl', 'DT', 'VERSION', 'RUNDATE','STATUS','LONIUID','LONIUID_BASE',\n",
    "                                             'VBSI','HBSI_R','HBSI_L', 'HBSI_T','HPACCEPT_R','HPACCEPT_L','ANN_HBSI']\n",
    "                                   )\n",
    "print(df_complete_trial.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(285, 56)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_complete_trial['TEMPQC']\n",
    "df_complete_2 = df_complete_trial.query(\"TEMPQC == 'Pass'\")\n",
    "\n",
    "missing_values = df_complete_2.isnull()\n",
    "missing_values.value_counts()\n",
    "#missing_values\n",
    "\n",
    "df_complete_3 = df_complete_2.dropna(axis=0, subset= ['TAU_INNO','ABETA_INNO','PTAU_INNO'])\n",
    "df_complete_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 5 - Identify complete case data\n",
    "The Event Based Model requires all features to be present for an observation to be included. Please remove any rows where one of the features that you plan to put in the EBM has missing data.\n",
    "\n",
    "Please remove any data which failed QC check. The key column to check is `TEMPQC`.\n",
    "\n",
    "Answer a few questions:\n",
    "* For each variable, how many subjects had missing data? \n",
    "* How many subjects remain? \n",
    "* How do the subjects break down across diagnosis?\n",
    "* Within diagnosis, how do they breakdown in terms of sex, age, APOE status?\n",
    "* How do these numbers compare to the paper? \n",
    "\n",
    "This should be your final data set, which should consist of 283 participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RID\n",
      "False    665\n",
      "Name: RID, dtype: int64\n",
      "----\n",
      "COLPROT\n",
      "False    665\n",
      "Name: COLPROT, dtype: int64\n",
      "----\n",
      "ORIGPROT\n",
      "False    665\n",
      "Name: ORIGPROT, dtype: int64\n",
      "----\n",
      "PTID\n",
      "False    665\n",
      "Name: PTID, dtype: int64\n",
      "----\n",
      "SITE\n",
      "False    665\n",
      "Name: SITE, dtype: int64\n",
      "----\n",
      "VISCODE\n",
      "False    665\n",
      "Name: VISCODE, dtype: int64\n",
      "----\n",
      "EXAMDATE\n",
      "False    665\n",
      "Name: EXAMDATE, dtype: int64\n",
      "----\n",
      "DX_bl\n",
      "False    665\n",
      "Name: DX_bl, dtype: int64\n",
      "----\n",
      "AGE\n",
      "False    665\n",
      "Name: AGE, dtype: int64\n",
      "----\n",
      "APOE4\n",
      "False    665\n",
      "Name: APOE4, dtype: int64\n",
      "----\n",
      "FDG\n",
      "True     333\n",
      "False    332\n",
      "Name: FDG, dtype: int64\n",
      "----\n",
      "ABETA_ELECSYS\n",
      "True     350\n",
      "False    315\n",
      "Name: ABETA_ELECSYS, dtype: int64\n",
      "----\n",
      "TAU_ELECSYS\n",
      "True     350\n",
      "False    315\n",
      "Name: TAU_ELECSYS, dtype: int64\n",
      "----\n",
      "PTAU_ELECSYS\n",
      "True     350\n",
      "False    315\n",
      "Name: PTAU_ELECSYS, dtype: int64\n",
      "----\n",
      "CDRSB\n",
      "False    665\n",
      "Name: CDRSB, dtype: int64\n",
      "----\n",
      "ADAS11\n",
      "False    665\n",
      "Name: ADAS11, dtype: int64\n",
      "----\n",
      "ADAS13\n",
      "False    660\n",
      "True       5\n",
      "Name: ADAS13, dtype: int64\n",
      "----\n",
      "ADASQ4\n",
      "False    665\n",
      "Name: ADASQ4, dtype: int64\n",
      "----\n",
      "MMSE\n",
      "False    665\n",
      "Name: MMSE, dtype: int64\n",
      "----\n",
      "RAVLT_immediate\n",
      "False    663\n",
      "True       2\n",
      "Name: RAVLT_immediate, dtype: int64\n",
      "----\n",
      "RAVLT_learning\n",
      "False    663\n",
      "True       2\n",
      "Name: RAVLT_learning, dtype: int64\n",
      "----\n",
      "RAVLT_forgetting\n",
      "False    663\n",
      "True       2\n",
      "Name: RAVLT_forgetting, dtype: int64\n",
      "----\n",
      "RAVLT_perc_forgetting\n",
      "False    660\n",
      "True       5\n",
      "Name: RAVLT_perc_forgetting, dtype: int64\n",
      "----\n",
      "MOCA\n",
      "True    665\n",
      "Name: MOCA, dtype: int64\n",
      "----\n",
      "FLDSTRENG\n",
      "False    665\n",
      "Name: FLDSTRENG, dtype: int64\n",
      "----\n",
      "IMAGEUID\n",
      "False    665\n",
      "Name: IMAGEUID, dtype: int64\n",
      "----\n",
      "Ventricles\n",
      "False    661\n",
      "True       4\n",
      "Name: Ventricles, dtype: int64\n",
      "----\n",
      "Hippocampus\n",
      "False    665\n",
      "Name: Hippocampus, dtype: int64\n",
      "----\n",
      "WholeBrain\n",
      "False    665\n",
      "Name: WholeBrain, dtype: int64\n",
      "----\n",
      "Entorhinal\n",
      "False    665\n",
      "Name: Entorhinal, dtype: int64\n",
      "----\n",
      "Fusiform\n",
      "False    665\n",
      "Name: Fusiform, dtype: int64\n",
      "----\n",
      "MidTemp\n",
      "False    665\n",
      "Name: MidTemp, dtype: int64\n",
      "----\n",
      "ICV\n",
      "False    665\n",
      "Name: ICV, dtype: int64\n",
      "----\n",
      "DX\n",
      "False    665\n",
      "Name: DX, dtype: int64\n",
      "----\n",
      "EXAMDATE_bl\n",
      "False    665\n",
      "Name: EXAMDATE_bl, dtype: int64\n",
      "----\n",
      "CDRSB_bl\n",
      "False    665\n",
      "Name: CDRSB_bl, dtype: int64\n",
      "----\n",
      "ADAS11_bl\n",
      "False    665\n",
      "Name: ADAS11_bl, dtype: int64\n",
      "----\n",
      "ADAS13_bl\n",
      "False    660\n",
      "True       5\n",
      "Name: ADAS13_bl, dtype: int64\n",
      "----\n",
      "ADASQ4_bl\n",
      "False    665\n",
      "Name: ADASQ4_bl, dtype: int64\n",
      "----\n",
      "MMSE_bl\n",
      "False    665\n",
      "Name: MMSE_bl, dtype: int64\n",
      "----\n",
      "RAVLT_immediate_bl\n",
      "False    663\n",
      "True       2\n",
      "Name: RAVLT_immediate_bl, dtype: int64\n",
      "----\n",
      "RAVLT_learning_bl\n",
      "False    663\n",
      "True       2\n",
      "Name: RAVLT_learning_bl, dtype: int64\n",
      "----\n",
      "RAVLT_forgetting_bl\n",
      "False    663\n",
      "True       2\n",
      "Name: RAVLT_forgetting_bl, dtype: int64\n",
      "----\n",
      "RAVLT_perc_forgetting_bl\n",
      "False    660\n",
      "True       5\n",
      "Name: RAVLT_perc_forgetting_bl, dtype: int64\n",
      "----\n",
      "mPACCdigit_bl\n",
      "False    665\n",
      "Name: mPACCdigit_bl, dtype: int64\n",
      "----\n",
      "mPACCtrailsB_bl\n",
      "False    665\n",
      "Name: mPACCtrailsB_bl, dtype: int64\n",
      "----\n",
      "FLDSTRENG_bl\n",
      "False    665\n",
      "Name: FLDSTRENG_bl, dtype: int64\n",
      "----\n",
      "FSVERSION_bl\n",
      "False    665\n",
      "Name: FSVERSION_bl, dtype: int64\n",
      "----\n",
      "IMAGEUID_bl\n",
      "False    665\n",
      "Name: IMAGEUID_bl, dtype: int64\n",
      "----\n",
      "Ventricles_bl\n",
      "False    661\n",
      "True       4\n",
      "Name: Ventricles_bl, dtype: int64\n",
      "----\n",
      "Hippocampus_bl\n",
      "False    665\n",
      "Name: Hippocampus_bl, dtype: int64\n",
      "----\n",
      "WholeBrain_bl\n",
      "False    665\n",
      "Name: WholeBrain_bl, dtype: int64\n",
      "----\n",
      "Entorhinal_bl\n",
      "False    665\n",
      "Name: Entorhinal_bl, dtype: int64\n",
      "----\n",
      "Fusiform_bl\n",
      "False    665\n",
      "Name: Fusiform_bl, dtype: int64\n",
      "----\n",
      "MidTemp_bl\n",
      "False    665\n",
      "Name: MidTemp_bl, dtype: int64\n",
      "----\n",
      "ICV_bl\n",
      "False    665\n",
      "Name: ICV_bl, dtype: int64\n",
      "----\n",
      "MOCA_bl\n",
      "True    665\n",
      "Name: MOCA_bl, dtype: int64\n",
      "----\n",
      "ABETA_bl\n",
      "True     350\n",
      "False    315\n",
      "Name: ABETA_bl, dtype: int64\n",
      "----\n",
      "TAU_bl\n",
      "True     350\n",
      "False    315\n",
      "Name: TAU_bl, dtype: int64\n",
      "----\n",
      "PTAU_bl\n",
      "True     350\n",
      "False    315\n",
      "Name: PTAU_bl, dtype: int64\n",
      "----\n",
      "Years_bl\n",
      "False    665\n",
      "Name: Years_bl, dtype: int64\n",
      "----\n",
      "Month_bl\n",
      "False    665\n",
      "Name: Month_bl, dtype: int64\n",
      "----\n",
      "Month\n",
      "False    665\n",
      "Name: Month, dtype: int64\n",
      "----\n",
      "M\n",
      "False    665\n",
      "Name: M, dtype: int64\n",
      "----\n",
      "update_stamp_x\n",
      "False    665\n",
      "Name: update_stamp_x, dtype: int64\n",
      "----\n",
      "TEMPQC\n",
      "False    665\n",
      "Name: TEMPQC, dtype: int64\n",
      "----\n",
      "TAU_INNO\n",
      "True     380\n",
      "False    285\n",
      "Name: TAU_INNO, dtype: int64\n",
      "----\n",
      "ABETA_INNO\n",
      "True     380\n",
      "False    285\n",
      "Name: ABETA_INNO, dtype: int64\n",
      "----\n",
      "PTAU_INNO\n",
      "True     380\n",
      "False    285\n",
      "Name: PTAU_INNO, dtype: int64\n",
      "----\n",
      "VISCODE2\n",
      "True    665\n",
      "Name: VISCODE2, dtype: int64\n",
      "----\n",
      "DT\n",
      "True    665\n",
      "Name: DT, dtype: int64\n",
      "----\n",
      "VERSION\n",
      "True    665\n",
      "Name: VERSION, dtype: int64\n",
      "----\n",
      "RUNDATE\n",
      "True    665\n",
      "Name: RUNDATE, dtype: int64\n",
      "----\n",
      "STATUS\n",
      "True    665\n",
      "Name: STATUS, dtype: int64\n",
      "----\n",
      "LONIUID\n",
      "True    665\n",
      "Name: LONIUID, dtype: int64\n",
      "----\n",
      "LONIUID_BASE\n",
      "True    665\n",
      "Name: LONIUID_BASE, dtype: int64\n",
      "----\n",
      "BRAINVOL\n",
      "True    665\n",
      "Name: BRAINVOL, dtype: int64\n",
      "----\n",
      "VENTVOL\n",
      "True    665\n",
      "Name: VENTVOL, dtype: int64\n",
      "----\n",
      "HIPPOVOL_R\n",
      "True    665\n",
      "Name: HIPPOVOL_R, dtype: int64\n",
      "----\n",
      "HIPPOVOL_L\n",
      "True    665\n",
      "Name: HIPPOVOL_L, dtype: int64\n",
      "----\n",
      "DBCBBSI\n",
      "True    665\n",
      "Name: DBCBBSI, dtype: int64\n",
      "----\n",
      "KMNDBCBBSI\n",
      "True    665\n",
      "Name: KMNDBCBBSI, dtype: int64\n",
      "----\n",
      "ANN_BBSI\n",
      "True    665\n",
      "Name: ANN_BBSI, dtype: int64\n",
      "----\n",
      "VBSI\n",
      "True    665\n",
      "Name: VBSI, dtype: int64\n",
      "----\n",
      "HBSI_R\n",
      "True    665\n",
      "Name: HBSI_R, dtype: int64\n",
      "----\n",
      "HBSI_L\n",
      "True    665\n",
      "Name: HBSI_L, dtype: int64\n",
      "----\n",
      "HBSI_T\n",
      "True    665\n",
      "Name: HBSI_T, dtype: int64\n",
      "----\n",
      "ANN_HBSI\n",
      "True    665\n",
      "Name: ANN_HBSI, dtype: int64\n",
      "----\n",
      "REGRATING\n",
      "True    665\n",
      "Name: REGRATING, dtype: int64\n",
      "----\n",
      "VENTACCEPT\n",
      "True    665\n",
      "Name: VENTACCEPT, dtype: int64\n",
      "----\n",
      "HPACCEPT_R\n",
      "True    665\n",
      "Name: HPACCEPT_R, dtype: int64\n",
      "----\n",
      "HPACCEPT_L\n",
      "True    665\n",
      "Name: HPACCEPT_L, dtype: int64\n",
      "----\n",
      "MRSEQUENCE\n",
      "True    665\n",
      "Name: MRSEQUENCE, dtype: int64\n",
      "----\n",
      "MRFIELD\n",
      "True    665\n",
      "Name: MRFIELD, dtype: int64\n",
      "----\n",
      "PROTOCOL\n",
      "True    665\n",
      "Name: PROTOCOL, dtype: int64\n",
      "----\n",
      "QC_PASS\n",
      "True    665\n",
      "Name: QC_PASS, dtype: int64\n",
      "----\n",
      "update_stamp_y\n",
      "True    665\n",
      "Name: update_stamp_y, dtype: int64\n",
      "----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(285, 97)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer to Step 5\n",
    "# Below put your code to remove missing data\n",
    "# and answer the descriptive statsitics queries\n",
    "# around the final data set\n",
    "\n",
    "df_complete['TEMPQC']\n",
    "df_complete = df_complete.query(\"TEMPQC == 'Pass'\")\n",
    "\n",
    "#missing_values = df_complete.isnull()\n",
    "#missing_values.value_counts()\n",
    "#missing_values\n",
    "\n",
    "for column in missing_values:  \n",
    "    print(column)\n",
    "    print(missing_values[column].value_counts())\n",
    "    print('----')\n",
    "\n",
    "df_complete_2 = df_complete.dropna(axis=0, subset= ['TAU_INNO','ABETA_INNO','PTAU_INNO'])\n",
    "df_complete_2.shape\n",
    "\n",
    "#df_complete = df_complete.reset_index(drop=True)\n",
    "\n",
    "#df_complete.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 6 - Data review\n",
    "We have looked at the final data set at a group level, but let's actually visualise the data. For the various features that are to be included in the EBM, create some plots of your choice to look at how these values differ between the cognitively normal individuals and those showing evidence of cognitive impairment. You can break this latter group into mild cognitive impairment and Alzheimer's disease if you wish. You can also look at how this varies with _APOE_ status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer to Step 6\n",
    "# Below put your code for visualising the data\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1ca3c52c2c6a741687ac119195f853fd55cbbadb57e664fb666b72dd14734ec5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
